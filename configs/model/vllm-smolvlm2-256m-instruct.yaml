defaults:
- vllm: default.yaml
- _self_

provider: vllm
model: HuggingFaceTB/SmolVLM2-256M-Instruct
api_env_var: null

parameters:
  temperature: 0.3
  max_tokens: 1024

vllm:
  parameters:
    max_model_len: 2048
    max_num_seqs: 1
  tool_call_parser: pythonic


